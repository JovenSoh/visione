services:
  ffmpeg:
    image: jrottenberg/ffmpeg:5.1.2-nvidia2004
    entrypoint: []
    volumes:
      - ${VISIONE_ROOT}:/data
      - ${VISIONE_CACHE}:/cache
    profiles: ["analysis", "ffmpeg"]
    deploy: &needs_gpu
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

  scene-detection:
    build: ./analysis/scene-detection
    image: visione/scene-detection
    volumes: &common_volumes
      - ${VISIONE_ROOT}:/data
      - ${VISIONE_CACHE}:/cache
      - ./common:/usr/src/visione:ro
    profiles: ["analysis", "scene-detection"]

  objects-colors:
    build: ./analysis/objects-colors
    image: visione/objects-colors
    volumes: *common_volumes
    profiles: ["analysis", "objects-colors"]

  objects-mrcnn-lvis:
    build: ./analysis/objects-mmdet
    image: visione/objects-mmdet
    environment: ["DETECTOR_NAME=mrcnn-lvis"]
    volumes: *common_volumes
    profiles: ["analysis", "objects-mrcnn-lvis"]
    deploy: *needs_gpu
  
  objects-vfnet64-coco:
    build: ./analysis/objects-mmdet
    image: visione/objects-mmdet
    environment: ["DETECTOR_NAME=vfnet64-coco"]
    volumes: *common_volumes
    profiles: ["analysis", "objects-vfnet64-coco"]
    deploy: *needs_gpu

  objects-frcnn-oiv4:
    build: ./analysis/objects-openimagesv4
    image: visione/objects-openimagesv4
    volumes: *common_volumes
    profiles: ["analysis", "objects-frcnn-oiv4"]
    deploy: *needs_gpu

  features-gem:
    build: ./analysis/features-gem
    image: visione/features-gem
    shm_size: 2GB
    volumes: *common_volumes
    profiles: ["analysis", "features-gem"]
    deploy: *needs_gpu

  features-clip-openai:
    build: ./analysis/features-clip
    image: visione/features-clip
    environment:
      - FEATURES_NAME=clip-openai
      - MODEL_HANDLE=openai/clip-vit-large-patch14
    deploy: *needs_gpu
    volumes: *common_volumes
    profiles: ["analysis", "features-clip-openai"]

  features-clip-laion:
    build: ./analysis/features-clip
    image: visione/features-clip
    environment:
      - FEATURES_NAME=clip-laion
      - MODEL_HANDLE=laion/CLIP-ViT-H-14-laion2B-s32B-b79K
    volumes: *common_volumes
    profiles: ["analysis", "features-clip-laion"]
    deploy: *needs_gpu
  
  features-clip-datacomp:
    build: ./analysis/features-clip
    image: visione/features-clip
    shm_size: 2g
    environment:
      - FEATURES_NAME=clip-datacomp
      - MODEL_HANDLE=laion/CLIP-ViT-L-14-DataComp.XL-s13B-b90K
    volumes: *common_volumes
    profiles: ["analysis", "features-clip-datacomp"]
    deploy: *needs_gpu

  features-biomed-clip:
    build: ./analysis/features-openclip
    image: visione/features-openclip
    environment:
      - FEATURES_NAME=biomed-clip
      - MODEL_HANDLE=hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224
    volumes: *common_volumes
    profiles: ["analysis", "features-biomed-clip"]
    deploy: *needs_gpu

  features-clip2video:
    build: ./analysis/features-clip2video
    image: visione/features-clip2video
    shm_size: 2g
    volumes: *common_volumes
    profiles: ["analysis", "features-clip2video"]
    deploy: *needs_gpu

  features-aladin:
    build:
      context: ./analysis/features-aladin
      secrets: ["asset_token"]
    image: visione/features-aladin
    volumes: *common_volumes
    shm_size: 2g
    profiles: ["analysis", "features-aladin"]
    deploy: *needs_gpu
  
  features-dinov2:
    build: ./analysis/features-dinov2
    image: visione/features-dinov2
    environment:
      - FEATURES_NAME=dinov2
      - MODEL=dinov2_vits14
    volumes: *common_volumes
    profiles: ["analysis", "features-dinov2"]
    deploy: *needs_gpu

  features-clipvip:
    build: ./analysis/features-clipvip
    image: visione/features-clipvip
    shm_size: 2g
    volumes: *common_volumes
    profiles: ["analysis", "features-clipvip"]
    deploy: *needs_gpu

  frame-cluster:
    build: ./analysis/frame-cluster
    image: visione/frame-cluster
    volumes: *common_volumes
    profiles: ["analysis", "frame-cluster"]

